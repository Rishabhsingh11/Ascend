"""Main Streamlit application for Ascend Resume Analyzer."""

import streamlit as st
from streamlit_option_menu import option_menu
import time
from pathlib import Path

# Import your existing components
from src.agent import JobSearchAgent
from src.google_drive_handler import GoogleDriveHandler
from src.document_store import DocumentStore
from src.config import get_settings
from src.logger import get_logger, set_logger, AgentLogger
from src.callbacks import StreamingCallbackHandler
from src.state import AgentState
from langchain_ollama import ChatOllama

from src.UI.streaming_utils import StreamlitTokenHandler, create_analysis_section, show_streaming_progress
from pathlib import Path

# Import UI components
from src.UI.components.results import render_results
from src.UI.components.cache_viewer import render_cache_stats


def init_session_state():
    """Initialize session state variables."""
    if 'processed_resume' not in st.session_state:
        st.session_state.processed_resume = None
    if 'selected_file' not in st.session_state:
        st.session_state.selected_file = None
    if 'agent' not in st.session_state:
        st.session_state.agent = None
    if 'drive_handler' not in st.session_state:
        st.session_state.drive_handler = None
    if 'enable_skill_gap' not in st.session_state:
        st.session_state.enable_skill_gap = True  # Default enabled
    if 'skill_gap_loading' not in st.session_state:
        st.session_state.skill_gap_loading = False


def load_custom_css():
    """Load custom CSS styling."""
    css_file = Path(__file__).parent / "styles" / "custom.css"
    
    # Additional inline CSS for text visibility
    inline_css = """
    <style>
        /* Force text visibility */
        .stExpander p, .stExpander div, .stExpander span {
            color: #1F2937 !important;
        }
        
        /* Fix markdown in expanders */
        .stExpander .stMarkdown {
            color: #1F2937 !important;
        }
        
        /* Ensure subheaders are visible */
        .stMarkdown h2, .stMarkdown h3 {
            color: #1E3A8A !important;
        }
    </style>
    """
    
    st.markdown(inline_css, unsafe_allow_html=True)
    
    # Load external CSS if exists
    if css_file.exists():
        with open(css_file, 'r') as f:
            st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)


def main():
    """Main Streamlit application."""
    
    # Page configuration
    st.set_page_config(
        page_title="Ascend - AI Resume Analyzer",
        page_icon="üöÄ",
        layout="wide",
        initial_sidebar_state="expanded",
        menu_items={
            'Get Help': 'https://github.com/Rishabhsingh11/Ascend-',
            'Report a bug': "https://github.com/Rishabhsingh11/Ascend-/issues",
            'About': "# Ascend Resume Analyzer\nAI-powered resume analysis and job matching tool."
        }
    )
    
    # Initialize session state
    init_session_state()
    
    # Load custom CSS
    load_custom_css()
    
    # Header
    st.markdown("""
        <div style='text-align: center; padding: 2rem 0;'>
            <h1 style='color: #1E3A8A; font-size: 3rem; margin-bottom: 0;'>
                üöÄ Ascend
            </h1>
            <p style='color: #64748B; font-size: 1.2rem; margin-top: 0.5rem;'>
                AI-Powered Resume Analysis & Job Matching Platform
            </p>
        </div>
    """, unsafe_allow_html=True)
    
    st.divider()
    
    # Navigation menu
    selected = option_menu(
        menu_title=None,
        options=["üì§ Upload Resume", "üìä Analysis Results", "üíæ Cache Manager", "‚ÑπÔ∏è About"],
        icons=['cloud-upload', 'bar-chart-fill', 'database-fill', 'info-circle'],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",
        styles={
            "container": {"padding": "0!important", "background-color": "#F8FAFC"},
            "icon": {"color": "#3B82F6", "font-size": "20px"}, 
            "nav-link": {
                "font-size": "16px",
                "text-align": "center",
                "margin": "0px",
                "--hover-color": "#E0E7FF",
            },
            "nav-link-selected": {"background-color": "#3B82F6"},
        }
    )
    
    # Render selected page
    if selected == "üì§ Upload Resume":
        render_upload_page()
    elif selected == "üìä Analysis Results":
        render_results_page()
    elif selected == "üíæ Cache Manager":
        render_cache_page()
    elif selected == "‚ÑπÔ∏è About":
        render_about_page()


def render_upload_page():
    """Render the resume upload page."""
    st.header("üì§ Upload & Analyze Resume")

    st.markdown("---")
    col_toggle1, col_toggle2 = st.columns([3, 1])
    with col_toggle1:
        st.markdown("### ‚öôÔ∏è Analysis Options")
        enable_skill_gap = st.checkbox(
            "üîç Enable Skill Gap Analysis",
            value=st.session_state.enable_skill_gap,
            help="Fetch real job postings and analyze skill gaps (adds 2-3 minutes)"
        )
        st.session_state.enable_skill_gap = enable_skill_gap
        
        if enable_skill_gap:
            st.info("‚ú® **Phase 2 Enabled:** Will fetch live job data and analyze skill gaps")
        else:
            st.warning("‚ö†Ô∏è **Phase 2 Disabled:** Only basic resume analysis will run")
    
    st.markdown("---")
    
    # Two-column layout
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Choose Upload Method")
        
        upload_method = st.radio(
            "Select method:",
            ["üìÅ Upload Local File", "‚òÅÔ∏è From Google Drive"],
            horizontal=True
        )
        
        if upload_method == "üìÅ Upload Local File":
            render_local_upload()
        else:
            render_drive_upload()
    
    with col2:
        st.subheader("‚ÑπÔ∏è How It Works")
        st.info("""
        **Step 1:** Upload your resume (PDF or DOCX)
        
        **Step 2:** Our AI analyzes:
        - üìù Contact information
        - üíº Work experience
        - üéì Education
        - üõ†Ô∏è Skills
        
        **Step 3:** Get insights:
        - üéØ Top 3 job matches
        - üìä Quality score
        - üí° Improvement tips
        
        **‚ö° Cached resumes load instantly!**
        """)


def render_local_upload():
    """Handle local file upload."""
    uploaded_file = st.file_uploader(
        "Choose a resume file",
        type=['pdf', 'docx'],
        help="Upload your resume in PDF or DOCX format"
    )
    
    if uploaded_file is not None:
        st.success(f"‚úÖ File uploaded: {uploaded_file.name}")
        
        # Save uploaded file temporarily
        temp_path = Path(f"temp_resumes/{uploaded_file.name}")
        temp_path.parent.mkdir(exist_ok=True)
        
        with open(temp_path, 'wb') as f:
            f.write(uploaded_file.getbuffer())
        
        if st.button("üöÄ Analyze Resume", type="primary", use_container_width=True):
            analyze_local_resume(str(temp_path), uploaded_file.name)  # NEW: Use streaming function



def render_drive_upload():
    """Handle Google Drive file selection."""
    
    # Initialize session state for drive resumes
    if 'drive_resumes' not in st.session_state:
        st.session_state.drive_resumes = None
    if 'drive_connected' not in st.session_state:
        st.session_state.drive_connected = False
    
    st.info("üîê Google Drive integration requires authentication")
    
    # Show connect button only if not connected
    if not st.session_state.drive_connected:
        if st.button("üîó Connect to Google Drive"):
            with st.spinner("Connecting to Google Drive..."):
                try:
                    settings = get_settings()
                    drive_handler = GoogleDriveHandler(settings.google_credentials_path)
                    st.session_state.drive_handler = drive_handler
                    
                    # List resumes
                    resumes = drive_handler.list_resumes(folder_name=settings.google_drive_folder_name)
                    
                    if resumes:
                        # Store resumes in session state
                        st.session_state.drive_resumes = resumes
                        st.session_state.drive_connected = True
                        st.success(f"‚úÖ Found {len(resumes)} resume(s)")
                        st.rerun()  # Rerun to show the selector
                    else:
                        st.warning("‚ö†Ô∏è No resumes found in Google Drive folder")
                        
                except Exception as e:
                    st.error(f"‚ùå Error connecting to Google Drive: {str(e)}")
                    st.exception(e)
    
    # Show resume selector if connected
    if st.session_state.drive_connected and st.session_state.drive_resumes:
        st.success(f"‚úÖ Connected - {len(st.session_state.drive_resumes)} resume(s) available")
        
        # Disconnect button
        if st.button("üîå Disconnect", type="secondary"):
            st.session_state.drive_connected = False
            st.session_state.drive_resumes = None
            st.session_state.drive_handler = None
            st.rerun()
        
        st.markdown("---")
        
        # Build resume options
        resume_options = {}
        for r in st.session_state.drive_resumes:
            # Safely handle file size
            size_kb = "Unknown"
            if r.get('size'):
                try:
                    size_kb = f"{int(r['size']) // 1024} KB"
                except (ValueError, TypeError):
                    size_kb = "Unknown"
            
            display_name = f"{r['name']} ({size_kb})"
            resume_options[display_name] = r
        
        # Resume selector
        selected = st.selectbox(
            "Select a resume to analyze:",
            list(resume_options.keys()),
            key="resume_selector"
        )
        
        # Analyze button
        if st.button("üì• Download & Analyze", type="primary", width='stretch'):
            resume = resume_options[selected]
            with st.spinner("Analyzing resume..."):
                analyze_resume_from_drive(resume['id'], resume['name'])
            
def analyze_local_resume(file_path: str, file_name: str):
    """Analyze locally uploaded resume with cache-aware streaming + Phase 2 skill gap.
    
    Flow:
    1. Parse resume (no download needed)
    2. Compute hash and check cache for Phase 1 results
    3. If cached: Load Phase 1 from cache (instant)
    4. If not cached: Run Phase 1 with real LLM and cache results
    5. ALWAYS run Phase 2 (job market data changes constantly)
    
    Args:
        file_path: Path to locally uploaded resume file
        file_name: Original filename
    """
    
    from src.UI.streaming_utils import (
        StreamlitTokenHandler, 
        create_analysis_section, 
        show_streaming_progress,
        simulate_streaming_from_cache
    )
    from pathlib import Path
    from src.document_store import DocumentStore
    from src.utils import hash_file
    import time
    
    # Create progress indicators
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    # Create expandable sections for streaming output
    parsing_expander, parsing_container = create_analysis_section(
        "üìÑ Resume Parsing", 
        icon="üìÑ", 
        expanded=True
    )
    
    roles_expander, roles_container = create_analysis_section(
        "üéØ Job Role Analysis",
        icon="üéØ",
        expanded=True
    )
    
    summary_expander, summary_container = create_analysis_section(
        "üìä Quality Assessment",
        icon="üìä",
        expanded=True
    )
    
    try:
        # ========== STEP 1: Initialize Agent ==========
        show_streaming_progress(
            "Initializing AI Agent",
            10,
            status_placeholder,
            progress_placeholder
        )
        
        if st.session_state.agent is None:
            from src.agent import JobSearchAgent
            st.session_state.agent = JobSearchAgent()
        
        time.sleep(0.3)
        
        # ========== STEP 2: Compute Hash & Check Cache ==========
        show_streaming_progress(
            "Computing resume hash & checking cache",
            20,
            status_placeholder,
            progress_placeholder
        )
        
        parsing_container.info(f"üìÑ Processing: {file_name}")
        
        resume_hash = hash_file(file_path)
        doc_store = DocumentStore()
        cached_data = doc_store.get_cached_resume(resume_hash)
        
        # Variables to store Phase 1 results
        parsed_resume = None
        job_matches = None
        summary = None
        raw_text = None
        
        # ========== CACHE HIT PATH (Load Phase 1 from cache) ==========
        if cached_data:
            st.success(f"üì¶ **Cache Hit!** Phase 1 loaded from {cached_data['created_at']}")
            st.info("‚ö° Loading cached Phase 1 results... Phase 2 will still run with live data")
            
            # Parse cached data
            from src.state import ParsedResume, JobRoleMatch, ResumeSummary
            
            parsed_resume = ParsedResume.model_validate(cached_data['parsed_data'])
            job_matches = [JobRoleMatch.model_validate(m) for m in cached_data['job_roles']]
            summary = ResumeSummary.model_validate(cached_data['summary'])
            
            # ===== Parsing Section =====
            show_streaming_progress("Loading cached parsing results", 30, status_placeholder, progress_placeholder)
            
            parsing_container.success("‚úÖ Resume parsed (from cache)")
            parsing_container.markdown(f"""
            **Extracted Information:**
            - **Name:** {parsed_resume.contact_info.name or 'N/A'}
            - **Email:** {parsed_resume.contact_info.email or 'N/A'}
            - **Skills:** {len(parsed_resume.skills)} identified
            - **Experience:** {len(parsed_resume.experience)} positions
            - **Education:** {len(parsed_resume.education)} degrees
            """)
            
            # ===== Job Roles Section (Simulated Streaming) =====
            show_streaming_progress("Simulating job role analysis (cached)", 50, status_placeholder, progress_placeholder)
            
            roles_text = "**Top 3 Job Role Recommendations:**\n\n"
            for idx, match in enumerate(job_matches, 1):
                roles_text += f"**{idx}. {match.role_title}**\n"
                roles_text += f"- **Confidence:** {match.confidence_score:.1%}\n"
                roles_text += f"- **Reasoning:** {match.reasoning}\n"
                roles_text += f"- **Matching Skills:** {', '.join(match.key_matching_skills[:5])}\n\n"
            
            simulate_streaming_from_cache(
                roles_container,
                roles_text,
                prefix="üì¶ Cached Analysis",
                chars_per_token=8,
                delay_ms=20
            )
            
            roles_container.success("‚úÖ Job role analysis complete (from cache)")
            
            # ===== Summary Section (Simulated Streaming) =====
            show_streaming_progress("Simulating quality assessment (cached)", 70, status_placeholder, progress_placeholder)
            
            summary_text = f"**Quality Score:** {summary.quality_score}/10\n\n"
            summary_text += f"**Summary:**\n{summary.overall_summary}\n\n"
            summary_text += f"**Years of Experience:** {summary.years_of_experience or 'N/A'}\n\n"
            summary_text += f"**Key Strengths:**\n"
            summary_text += '\n'.join([f"- {s}" for s in summary.key_strengths]) + "\n\n"
            summary_text += f"**Improvement Suggestions:**\n"
            summary_text += '\n'.join([f"- {s}" for s in summary.improvement_suggestions])
            
            if summary.grammatical_issues:
                summary_text += f"\n\n**Grammatical Issues:**\n"
                summary_text += '\n'.join([f"- {i}" for i in summary.grammatical_issues])
            
            simulate_streaming_from_cache(
                summary_container,
                summary_text,
                prefix="üì¶ Cached Assessment",
                chars_per_token=8,
                delay_ms=20
            )
            
            summary_container.success("‚úÖ Quality assessment complete (from cache)")
            
            # Need raw_text for Phase 2, extract it
            from src.resume_parser import ResumeTextExtractor
            text_extractor = ResumeTextExtractor()
            raw_text = text_extractor.extract_text(file_path)
        
        # ========== CACHE MISS PATH (Run Phase 1 with LLM) ==========
        else:
            st.info("üîÑ **Cache Miss** - Running full Phase 1 analysis (10-15 minutes)")
            
            # ===== Parse Resume =====
            show_streaming_progress("Parsing resume structure (PDFPlumber)", 30, status_placeholder, progress_placeholder)
            
            from src.enhanced_resume_parser import EnhancedResumeParser
            from src.resume_parser import ResumeTextExtractor
            
            parser = EnhancedResumeParser(file_path=file_path, debug=False)
            parsed_resume = parser.parse()
            
            text_extractor = ResumeTextExtractor()
            raw_text = text_extractor.extract_text(file_path)
            
            parsing_container.success("‚úÖ Resume parsed successfully")
            parsing_container.markdown(f"""
            **Extracted Information:**
            - **Name:** {parsed_resume.contact_info.name or 'N/A'}
            - **Email:** {parsed_resume.contact_info.email or 'N/A'}
            - **Skills:** {len(parsed_resume.skills)} identified
            - **Experience:** {len(parsed_resume.experience)} positions
            - **Education:** {len(parsed_resume.education)} degrees
            """)
            
            # ===== Analyze Job Roles with REAL LLM STREAMING =====
            show_streaming_progress("Analyzing job role fit (LLM streaming - ~6 minutes)", 50, status_placeholder, progress_placeholder)
            
            from src.state import AgentState
            from langchain_core.messages import HumanMessage
            
            current_state = {
                'messages': [HumanMessage(content=f"Processing {file_name}")],
                'file_id': 'local',
                'file_name': file_name,
                'raw_resume_text': raw_text,
                'parsed_resume': parsed_resume,
                'job_role_matches': None,
                'resume_summary': None,
                'current_step': 'parsing_complete',
                'error': None
            }
            
            roles_handler = StreamlitTokenHandler(
                roles_container,
                prefix="ü§ñ AI Analysis in Progress (Live Streaming)..."
            )
            
            roles_result = st.session_state.agent._analyze_job_roles_streaming(
                current_state,
                token_callback=roles_handler.on_token
            )
            
            if roles_result.get('error'):
                roles_container.error(f"‚ùå Analysis failed: {roles_result['error']}")
                doc_store.close()
                return
            
            roles_handler.clear()
            roles_container.success("‚úÖ Job role analysis complete")
            
            job_matches = roles_result['job_role_matches']
            for idx, match in enumerate(job_matches, 1):
                roles_container.markdown(f"""
                **{idx}. {match.role_title}**
                - **Confidence:** {match.confidence_score:.1%}
                - **Reasoning:** {match.reasoning}
                - **Matching Skills:** {', '.join(match.key_matching_skills[:5])}
                """)
            
            # ===== Generate Summary with REAL LLM STREAMING =====
            show_streaming_progress("Generating quality assessment (LLM streaming - ~8 minutes)", 70, status_placeholder, progress_placeholder)
            
            current_state['job_role_matches'] = job_matches
            current_state['current_step'] = 'analysis_complete'
            
            summary_handler = StreamlitTokenHandler(
                summary_container,
                prefix="ü§ñ AI Review in Progress (Live Streaming)..."
            )
            
            summary_result = st.session_state.agent._generate_summary_streaming(
                current_state,
                token_callback=summary_handler.on_token
            )
            
            if summary_result.get('error'):
                summary_container.error(f"‚ùå Summary failed: {summary_result['error']}")
                doc_store.close()
                return
            
            summary_handler.clear()
            summary_container.success("‚úÖ Quality assessment complete")
            
            summary = summary_result['resume_summary']
            summary_container.markdown(f"""
            **Quality Score:** {summary.quality_score}/10
            
            **Summary:**
            {summary.overall_summary}
            
            **Years of Experience:** {summary.years_of_experience or 'N/A'}
            
            **Key Strengths:**
            {chr(10).join(['- ' + s for s in summary.key_strengths])}
            
            **Improvement Suggestions:**
            {chr(10).join(['- ' + s for s in summary.improvement_suggestions])}
            
            **Grammatical Issues:**
            {chr(10).join(['- ' + i for i in summary.grammatical_issues]) if summary.grammatical_issues else '- None found'}
            """)
            
            # ===== Save Phase 1 to Cache =====
            st.info("üíæ Saving Phase 1 results to cache...")
            
            doc_store.save_cached_resume(
                resume_hash=resume_hash,
                file_name=file_name,
                parsed_data=parsed_resume.model_dump(),
                job_roles=[match.model_dump() for match in job_matches],
                summary=summary.model_dump()
            )
            
            st.success("‚úÖ Phase 1 cached - future loads will be instant!")
        
        # ========== PHASE 2: SKILL GAP ANALYSIS (ALWAYS RUNS) ==========
        # Initialize result variables
        job_postings = []
        skill_gap_analysis = None
        
        if st.session_state.enable_skill_gap:
            st.markdown("---")
            st.subheader("üîç Phase 2: Skill Gap Analysis")
            st.info("üì° Phase 2 always runs with live job market data (not cached)")
            
            jobs_expander = st.expander("üìã Job Postings", expanded=True)
            gaps_expander = st.expander("üìä Skill Gap Analysis", expanded=True)
            
            with jobs_expander:
                jobs_container = st.container()
            
            with gaps_expander:
                gaps_container = st.container()
            
            try:
                # ===== Fetch Job Postings =====
                show_streaming_progress(
                    "Fetching live job postings from APIs",
                    80,
                    status_placeholder,
                    progress_placeholder
                )
                
                jobs_container.info("üåê Fetching job postings for your top 3 recommended roles...")
                
                # Build Phase 2 state
                phase2_state = {
                    'messages': [],
                    'file_id': 'local',
                    'file_name': file_name,
                    'raw_resume_text': raw_text,
                    'parsed_resume': parsed_resume,
                    'job_role_matches': job_matches,
                    'resume_summary': summary,
                    'current_step': 'complete',
                    'error': None,
                    'job_postings': [],
                    'skill_gap_analysis': None,
                    'enable_skill_gap': True
                }
                
                # Fetch jobs
                job_fetch_result = st.session_state.agent._fetch_job_postings(phase2_state)
                
                if job_fetch_result.get('error'):
                    jobs_container.warning(f"‚ö†Ô∏è Could not fetch jobs: {job_fetch_result['error']}")
                else:
                    job_postings = job_fetch_result.get('job_postings', [])
                    
                    if job_postings:
                        jobs_container.success(f"‚úÖ Fetched {len(job_postings)} job postings")
                        
                        # Show job summary by role
                        jobs_by_role = {}
                        for job in job_postings:
                            matched_role = None
                            for role_match in job_matches:
                                if any(word.lower() in job.title.lower() 
                                      for word in role_match.role_title.split() 
                                      if len(word) > 3):
                                    matched_role = role_match.role_title
                                    break
                            
                            if matched_role:
                                if matched_role not in jobs_by_role:
                                    jobs_by_role[matched_role] = []
                                jobs_by_role[matched_role].append(job)
                        
                        for role, role_jobs in jobs_by_role.items():
                            with jobs_container.expander(f"üìå {role} ({len(role_jobs)} jobs)", expanded=False):
                                for idx, job in enumerate(role_jobs[:3], 1):
                                    st.markdown(f"""
                                    **{idx}. {job.title}** @ {job.company}
                                    - üìç {job.location}
                                    - üí∞ {job.salary or 'Not specified'}
                                    - üîó [Apply]({job.url})
                                    """)
                        
                        # ===== Analyze Skill Gaps =====
                        show_streaming_progress(
                            "Analyzing skill gaps",
                            90,
                            status_placeholder,
                            progress_placeholder
                        )
                        
                        gaps_container.info("üß† Analyzing your skills vs market requirements...")
                        
                        phase2_state['job_postings'] = job_postings
                        skill_gap_result = st.session_state.agent._analyze_skill_gaps(phase2_state)
                        
                        if skill_gap_result.get('error'):
                            gaps_container.error(f"‚ùå Skill gap analysis failed: {skill_gap_result['error']}")
                        else:
                            skill_gap_analysis = skill_gap_result.get('skill_gap_analysis')
                            
                            if skill_gap_analysis:
                                gaps_container.success("‚úÖ Skill gap analysis complete!")
                                
                                gaps_container.metric(
                                    "üìä Overall Market Readiness",
                                    f"{skill_gap_analysis.overall_market_readiness}%"
                                )
                                
                                gaps_container.markdown(f"""
                                **Analysis Summary:**
                                - üìà Jobs Analyzed: {skill_gap_analysis.total_jobs_analyzed}
                                - üéØ Roles Evaluated: {len(skill_gap_analysis.role_analyses)}
                                - üö® Common Gaps: {len(skill_gap_analysis.common_gaps)}
                                - ‚ö° Quick Wins: {len(skill_gap_analysis.quick_wins)}
                                - üìÖ Date: {skill_gap_analysis.analysis_date}
                                """)
                                
                                gaps_container.info("üëâ Go to **Analysis Results** to see detailed insights")
                    else:
                        jobs_container.warning("‚ö†Ô∏è No job postings found")
                        
            except Exception as e:
                st.error(f"‚ùå Phase 2 error: {str(e)}")
                with st.expander("üêõ Error Details"):
                    st.exception(e)
        
        # ===== Complete & Store Results =====
        show_streaming_progress("Analysis complete!", 100, status_placeholder, progress_placeholder)
        
        # Store complete results in session state (INCLUDING Phase 2)
        st.session_state.processed_resume = {
            'parsed_resume': parsed_resume,
            'job_role_matches': job_matches,
            'resume_summary': summary,
            'job_postings': job_postings,  # NEW: Phase 2 data
            'skill_gap_analysis': skill_gap_analysis,  # NEW: Phase 2 data
            'file_name': file_name,
            'current_step': 'complete',
            'error': None,
            'enable_skill_gap': st.session_state.enable_skill_gap
        }
        
        # Cleanup
        doc_store.close()
        
        temp_file = Path(file_path)
        if temp_file.exists():
            temp_file.unlink()
        
        time.sleep(1)
        st.success("üéâ Resume analyzed successfully!")
        st.balloons()
        
        progress_placeholder.empty()
        status_placeholder.empty()
        
        st.info("üëâ Go to **Analysis Results** tab to view complete insights")
        
    except Exception as e:
        st.error(f"‚ùå Error analyzing resume: {str(e)}")
        progress_placeholder.empty()
        status_placeholder.empty()
        
        with st.expander("üêõ Error Details"):
            st.exception(e)



def analyze_resume(file_path: str, file_name: str):
    """Analyze a resume file."""
    
    # Progress bar
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # Initialize agent if not exists
        if st.session_state.agent is None:
            status_text.text("ü§ñ Initializing AI Agent...")
            progress_bar.progress(20)
            st.session_state.agent = JobSearchAgent()
        
        status_text.text("üìÑ Processing resume...")
        progress_bar.progress(40)
        
        # Process resume
        result = st.session_state.agent.process_resume(
            file_id="local",
            file_name=file_name
        )
        
        progress_bar.progress(100)
        status_text.text("‚úÖ Analysis complete!")
        
        # Store result in session state
        st.session_state.processed_resume = result
        
        time.sleep(1)
        st.success("üéâ Resume analyzed successfully!")
        st.balloons()
        
        # Switch to results tab
        st.info("üëâ Go to **Analysis Results** tab to view detailed insights")
        
    except Exception as e:
        st.error(f"‚ùå Error analyzing resume: {str(e)}")
        progress_bar.empty()
        status_text.empty()


def analyze_resume_from_drive(file_id: str, file_name: str):
    """Analyze resume from Google Drive with cache-aware streaming + Phase 2 skill gap.
    
    Flow:
    1. Download & parse resume
    2. Compute hash and check cache for Phase 1
    3. If cached: Load Phase 1 instantly (simulated streaming)
    4. If not cached: Run Phase 1 with real LLM streaming and cache results
    5. ALWAYS run Phase 2 with live job market data (never cached)
    
    Args:
        file_id: Google Drive file ID
        file_name: Resume filename
    """
    
    from src.UI.streaming_utils import (
        StreamlitTokenHandler, 
        create_analysis_section, 
        show_streaming_progress,
        simulate_streaming_from_cache
    )
    from pathlib import Path
    from src.document_store import DocumentStore
    from src.utils import hash_file
    import time
    
    # Create progress indicators
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    
    # Create expandable sections for streaming output
    parsing_expander, parsing_container = create_analysis_section(
        "üìÑ Resume Parsing", 
        icon="üìÑ", 
        expanded=True
    )
    
    roles_expander, roles_container = create_analysis_section(
        "üéØ Job Role Analysis",
        icon="üéØ",
        expanded=True
    )
    
    summary_expander, summary_container = create_analysis_section(
        "üìä Quality Assessment",
        icon="üìä",
        expanded=True
    )
    
    try:
        # ========== STEP 1: Initialize Agent ==========
        show_streaming_progress(
            "Initializing AI Agent",
            10,
            status_placeholder,
            progress_placeholder
        )
        
        if st.session_state.agent is None:
            from src.agent import JobSearchAgent
            st.session_state.agent = JobSearchAgent()
        
        time.sleep(0.3)
        
        # ========== STEP 2: Download Resume ==========
        show_streaming_progress(
            "Downloading from Google Drive",
            15,
            status_placeholder,
            progress_placeholder
        )
        
        drive_handler = st.session_state.drive_handler
        
        # Create temp directory
        temp_dir = Path("temp_resumes")
        temp_dir.mkdir(exist_ok=True)
        temp_file_path = temp_dir / file_name
        
        # Download file
        file_content = drive_handler.download_file(file_id, str(temp_file_path))
        
        parsing_container.success(f"‚úÖ Downloaded: {file_name}")
        
        # ========== STEP 3: Compute Hash & Check Cache ==========
        show_streaming_progress(
            "Computing resume hash & checking cache",
            20,
            status_placeholder,
            progress_placeholder
        )
        
        resume_hash = hash_file(str(temp_file_path))
        
        # Initialize document store
        doc_store = DocumentStore()
        cached_data = doc_store.get_cached_resume(resume_hash)
        
        # Variables to store Phase 1 results
        parsed_resume = None
        job_matches = None
        summary = None
        raw_text = None
        
        # ========== CACHE HIT PATH (Load Phase 1 from Cache) ==========
        if cached_data:
            st.success(f"üì¶ **Cache Hit!** Phase 1 loaded from {cached_data['created_at']}")
            st.info("‚ö° Loading cached Phase 1 results... Phase 2 will still run with live job market data")
            
            # Parse cached data
            from src.state import ParsedResume, JobRoleMatch, ResumeSummary
            
            parsed_resume = ParsedResume.model_validate(cached_data['parsed_data'])
            job_matches = [JobRoleMatch.model_validate(m) for m in cached_data['job_roles']]
            summary = ResumeSummary.model_validate(cached_data['summary'])
            
            # ===== Parsing Section =====
            show_streaming_progress(
                "Loading cached parsing results",
                30,
                status_placeholder,
                progress_placeholder
            )
            
            parsing_container.success("‚úÖ Resume parsed (from cache)")
            parsing_container.markdown(f"""
            **Extracted Information:**
            - **Name:** {parsed_resume.contact_info.name or 'N/A'}
            - **Email:** {parsed_resume.contact_info.email or 'N/A'}
            - **Skills:** {len(parsed_resume.skills)} identified
            - **Experience:** {len(parsed_resume.experience)} positions
            - **Education:** {len(parsed_resume.education)} degrees
            """)
            
            # ===== Job Roles Section (Simulated Streaming) =====
            show_streaming_progress(
                "Simulating job role analysis (cached)",
                50,
                status_placeholder,
                progress_placeholder
            )
            
            # Build text representation of job roles for streaming
            roles_text = "**Top 3 Job Role Recommendations:**\n\n"
            for idx, match in enumerate(job_matches, 1):
                roles_text += f"**{idx}. {match.role_title}**\n"
                roles_text += f"- **Confidence:** {match.confidence_score:.1%}\n"
                roles_text += f"- **Reasoning:** {match.reasoning}\n"
                roles_text += f"- **Matching Skills:** {', '.join(match.key_matching_skills[:5])}\n\n"
            
            # Simulate streaming
            simulate_streaming_from_cache(
                roles_container,
                roles_text,
                prefix="üì¶ Cached Analysis",
                chars_per_token=8,
                delay_ms=20
            )
            
            roles_container.success("‚úÖ Job role analysis complete (from cache)")
            
            # ===== Summary Section (Simulated Streaming) =====
            show_streaming_progress(
                "Simulating quality assessment (cached)",
                65,
                status_placeholder,
                progress_placeholder
            )
            
            # Build text representation of summary
            summary_text = f"**Quality Score:** {summary.quality_score}/10\n\n"
            summary_text += f"**Summary:**\n{summary.overall_summary}\n\n"
            summary_text += f"**Years of Experience:** {summary.years_of_experience or 'N/A'}\n\n"
            summary_text += f"**Key Strengths:**\n"
            summary_text += '\n'.join([f"- {s}" for s in summary.key_strengths]) + "\n\n"
            summary_text += f"**Improvement Suggestions:**\n"
            summary_text += '\n'.join([f"- {s}" for s in summary.improvement_suggestions])
            
            if summary.grammatical_issues:
                summary_text += f"\n\n**Grammatical Issues:**\n"
                summary_text += '\n'.join([f"- {i}" for i in summary.grammatical_issues])
            
            # Simulate streaming
            simulate_streaming_from_cache(
                summary_container,
                summary_text,
                prefix="üì¶ Cached Assessment",
                chars_per_token=8,
                delay_ms=20
            )
            
            summary_container.success("‚úÖ Quality assessment complete (from cache)")
            
            # Extract raw text for Phase 2
            from src.resume_parser import ResumeTextExtractor
            text_extractor = ResumeTextExtractor()
            raw_text = text_extractor.extract_text(str(temp_file_path))
        
        # ========== CACHE MISS PATH (Run Phase 1 with REAL LLM) ==========
        else:
            st.info("üîÑ **Cache Miss** - Running full Phase 1 analysis (10-15 minutes)")
            
            # ===== Parse Resume =====
            show_streaming_progress(
                "Parsing resume structure (PDFPlumber)",
                30,
                status_placeholder,
                progress_placeholder
            )
            
            from src.enhanced_resume_parser import EnhancedResumeParser
            from src.resume_parser import ResumeTextExtractor
            
            parser = EnhancedResumeParser(file_path=str(temp_file_path), debug=False)
            parsed_resume = parser.parse()
            
            text_extractor = ResumeTextExtractor()
            raw_text = text_extractor.extract_text(str(temp_file_path))
            
            parsing_container.success("‚úÖ Resume parsed successfully")
            parsing_container.markdown(f"""
            **Extracted Information:**
            - **Name:** {parsed_resume.contact_info.name or 'N/A'}
            - **Email:** {parsed_resume.contact_info.email or 'N/A'}
            - **Skills:** {len(parsed_resume.skills)} identified
            - **Experience:** {len(parsed_resume.experience)} positions
            - **Education:** {len(parsed_resume.education)} degrees
            """)
            
            # ===== Analyze Job Roles with REAL LLM STREAMING =====
            show_streaming_progress(
                "Analyzing job role fit (LLM streaming - ~6 minutes)",
                50,
                status_placeholder,
                progress_placeholder
            )
            
            from src.state import AgentState
            from langchain_core.messages import HumanMessage
            
            current_state = {
                'messages': [HumanMessage(content=f"Processing {file_name}")],
                'file_id': file_id,
                'file_name': file_name,
                'raw_resume_text': raw_text,
                'parsed_resume': parsed_resume,
                'job_role_matches': None,
                'resume_summary': None,
                'current_step': 'parsing_complete',
                'error': None
            }
            
            # Setup streaming handler for job roles
            roles_handler = StreamlitTokenHandler(
                roles_container,
                prefix="ü§ñ AI Analysis in Progress (Live Streaming)..."
            )
            
            # Call streaming analysis
            roles_result = st.session_state.agent._analyze_job_roles_streaming(
                current_state,
                token_callback=roles_handler.on_token
            )
            
            if roles_result.get('error'):
                roles_container.error(f"‚ùå Analysis failed: {roles_result['error']}")
                doc_store.close()
                if temp_file_path.exists():
                    temp_file_path.unlink()
                return
            
            roles_handler.clear()
            roles_container.success("‚úÖ Job role analysis complete")
            
            # Display structured results
            job_matches = roles_result['job_role_matches']
            for idx, match in enumerate(job_matches, 1):
                roles_container.markdown(f"""
                **{idx}. {match.role_title}**
                - **Confidence:** {match.confidence_score:.1%}
                - **Reasoning:** {match.reasoning}
                - **Matching Skills:** {', '.join(match.key_matching_skills[:5])}
                """)
            
            # ===== Generate Summary with REAL LLM STREAMING =====
            show_streaming_progress(
                "Generating quality assessment (LLM streaming - ~8 minutes)",
                65,
                status_placeholder,
                progress_placeholder
            )
            
            current_state['job_role_matches'] = job_matches
            current_state['current_step'] = 'analysis_complete'
            
            # Setup streaming handler for summary
            summary_handler = StreamlitTokenHandler(
                summary_container,
                prefix="ü§ñ AI Review in Progress (Live Streaming)..."
            )
            
            # Call streaming summary generation
            summary_result = st.session_state.agent._generate_summary_streaming(
                current_state,
                token_callback=summary_handler.on_token
            )
            
            if summary_result.get('error'):
                summary_container.error(f"‚ùå Summary failed: {summary_result['error']}")
                doc_store.close()
                if temp_file_path.exists():
                    temp_file_path.unlink()
                return
            
            summary_handler.clear()
            summary_container.success("‚úÖ Quality assessment complete")
            
            summary = summary_result['resume_summary']
            summary_container.markdown(f"""
            **Quality Score:** {summary.quality_score}/10
            
            **Summary:**
            {summary.overall_summary}
            
            **Years of Experience:** {summary.years_of_experience or 'N/A'}
            
            **Key Strengths:**
            {chr(10).join(['- ' + s for s in summary.key_strengths])}
            
            **Improvement Suggestions:**
            {chr(10).join(['- ' + s for s in summary.improvement_suggestions])}
            
            **Grammatical Issues:**
            {chr(10).join(['- ' + i for i in summary.grammatical_issues]) if summary.grammatical_issues else '- None found'}
            """)
            
            # ===== Save Phase 1 to Cache =====
            show_streaming_progress(
                "Saving Phase 1 results to cache",
                70,
                status_placeholder,
                progress_placeholder
            )
            
            st.info("üíæ Saving Phase 1 results to cache for future instant access...")
            
            doc_store.save_cached_resume(
                resume_hash=resume_hash,
                file_name=file_name,
                parsed_data=parsed_resume.model_dump(),
                job_roles=[match.model_dump() for match in job_matches],
                summary=summary.model_dump()
            )
            
            st.success("‚úÖ Phase 1 cached - future loads will be instant!")
        
        # ========== PHASE 2: SKILL GAP ANALYSIS (ALWAYS RUNS) ==========
        # Initialize Phase 2 result variables
        job_postings = []
        skill_gap_analysis = None
        
        if st.session_state.enable_skill_gap:
            st.markdown("---")
            st.subheader("üîç Phase 2: Skill Gap Analysis")
            st.info("üì° Phase 2 always runs with live job market data (not cached)")
            
            # Create Phase 2 expandable sections
            jobs_expander = st.expander("üìã Job Postings", expanded=True)
            gaps_expander = st.expander("üìä Skill Gap Analysis", expanded=True)
            
            with jobs_expander:
                jobs_container = st.container()
            
            with gaps_expander:
                gaps_container = st.container()
            
            try:
                # ===== Fetch Job Postings =====
                show_streaming_progress(
                    "Fetching live job postings from APIs (Adzuna, JSearch, Jooble)",
                    75,
                    status_placeholder,
                    progress_placeholder
                )
                
                jobs_container.info("üåê Fetching job postings for your top 3 recommended roles...")
                
                # Build Phase 2 state
                phase2_state = {
                    'messages': [],
                    'file_id': file_id,
                    'file_name': file_name,
                    'raw_resume_text': raw_text,
                    'parsed_resume': parsed_resume,
                    'job_role_matches': job_matches,
                    'resume_summary': summary,
                    'current_step': 'complete',
                    'error': None,
                    'job_postings': [],
                    'skill_gap_analysis': None,
                    'enable_skill_gap': True
                }
                
                # Fetch jobs
                job_fetch_result = st.session_state.agent._fetch_job_postings(phase2_state)
                
                if job_fetch_result.get('error'):
                    jobs_container.warning(f"‚ö†Ô∏è Could not fetch jobs: {job_fetch_result['error']}")
                    jobs_container.info("Continuing without skill gap analysis...")
                else:
                    job_postings = job_fetch_result.get('job_postings', [])
                    
                    if job_postings:
                        jobs_container.success(f"‚úÖ Fetched {len(job_postings)} job postings")
                        
                        # Show job summary by role
                        jobs_by_role = {}
                        for job in job_postings:
                            # Group by role based on title
                            matched_role = None
                            for role_match in job_matches:
                                if any(word.lower() in job.title.lower() 
                                      for word in role_match.role_title.split() 
                                      if len(word) > 3):
                                    matched_role = role_match.role_title
                                    break
                            
                            if matched_role:
                                if matched_role not in jobs_by_role:
                                    jobs_by_role[matched_role] = []
                                jobs_by_role[matched_role].append(job)
                        
                        # Display job summary
                        for role, role_jobs in jobs_by_role.items():
                            with jobs_container.expander(f"üìå {role} ({len(role_jobs)} jobs)", expanded=False):
                                for idx, job in enumerate(role_jobs[:3], 1):  # Show first 3
                                    st.markdown(f"""
                                    **{idx}. {job.title}** @ {job.company}
                                    - üìç {job.location}
                                    - üí∞ {job.salary or 'Not specified'}
                                    - üîó [Apply]({job.url})
                                    """)
                        
                        # ===== Analyze Skill Gaps =====
                        show_streaming_progress(
                            "Analyzing skill gaps against market requirements",
                            88,
                            status_placeholder,
                            progress_placeholder
                        )
                        
                        gaps_container.info("üß† Analyzing your skills vs market requirements...")
                        
                        phase2_state['job_postings'] = job_postings
                        skill_gap_result = st.session_state.agent._analyze_skill_gaps(phase2_state)
                        
                        if skill_gap_result.get('error'):
                            gaps_container.error(f"‚ùå Skill gap analysis failed: {skill_gap_result['error']}")
                        else:
                            skill_gap_analysis = skill_gap_result.get('skill_gap_analysis')
                            
                            if skill_gap_analysis:
                                gaps_container.success("‚úÖ Skill gap analysis complete!")
                                
                                # Display summary metrics
                                col1, col2, col3 = gaps_container.columns(3)
                                
                                with col1:
                                    st.metric(
                                        "Market Readiness",
                                        f"{skill_gap_analysis.overall_market_readiness}%"
                                    )
                                
                                with col2:
                                    st.metric(
                                        "Jobs Analyzed",
                                        skill_gap_analysis.total_jobs_analyzed
                                    )
                                
                                with col3:
                                    st.metric(
                                        "Common Gaps",
                                        len(skill_gap_analysis.common_gaps)
                                    )
                                
                                gaps_container.markdown(f"""
                                **Quick Summary:**
                                - üéØ Roles Evaluated: {len(skill_gap_analysis.role_analyses)}
                                - ‚ö° Quick Wins: {len(skill_gap_analysis.quick_wins)}
                                - üéì Long-term Goals: {len(skill_gap_analysis.long_term_goals)}
                                - üìÖ Analysis Date: {skill_gap_analysis.analysis_date}
                                """)
                                
                                gaps_container.info("üëâ Go to **Analysis Results** tab to see detailed skill gap insights")
                            else:
                                gaps_container.warning("‚ö†Ô∏è Skill gap analysis returned no results")
                    else:
                        jobs_container.warning("‚ö†Ô∏è No job postings found for your recommended roles")
                        
            except Exception as e:
                st.error(f"‚ùå Phase 2 error: {str(e)}")
                with st.expander("üêõ Phase 2 Error Details"):
                    st.exception(e)
        
        # ========== Complete & Store Results ==========
        show_streaming_progress(
            "Analysis complete!",
            100,
            status_placeholder,
            progress_placeholder
        )
        
        # Store complete results in session state (INCLUDING Phase 2)
        st.session_state.processed_resume = {
            'parsed_resume': parsed_resume,
            'job_role_matches': job_matches,
            'resume_summary': summary,
            'job_postings': job_postings,  # NEW: Phase 2 data
            'skill_gap_analysis': skill_gap_analysis,  # NEW: Phase 2 data
            'file_name': file_name,
            'current_step': 'complete',
            'error': None,
            'enable_skill_gap': st.session_state.enable_skill_gap
        }
        
        # Cleanup
        doc_store.close()
        if temp_file_path.exists():
            temp_file_path.unlink()
        
        time.sleep(1)
        st.success("üéâ Resume analyzed successfully!")
        st.balloons()
        
        # Clear progress indicators
        progress_placeholder.empty()
        status_placeholder.empty()
        
        st.info("üëâ Go to **Analysis Results** tab to view complete insights including skill gap analysis")
        
    except Exception as e:
        st.error(f"‚ùå Error analyzing resume: {str(e)}")
        progress_placeholder.empty()
        status_placeholder.empty()
        
        with st.expander("üêõ Error Details"):
            st.exception(e)




def render_results_page():
    """Render analysis results page."""
    if st.session_state.processed_resume is None:
        st.info("üì§ Please upload and analyze a resume first")
        return
    
    render_results(st.session_state.processed_resume)


def render_cache_page():
    """Render cache statistics page."""
    st.header("üíæ Cache Manager")
    render_cache_stats()


def render_about_page():
    """Render about page."""
    st.header("‚ÑπÔ∏è About Ascend")
    
    st.markdown("""
    ## üöÄ What is Ascend?
    
    Ascend is an AI-powered resume analysis platform that helps job seekers:
    - üìä Get detailed resume analysis
    - üéØ Find matching job roles
    - üí° Receive improvement suggestions
    - ‚ö° Leverage intelligent caching for fast results
    
    ## üõ†Ô∏è Technology Stack
    
    - **Frontend:** Streamlit
    - **AI/ML:** Ollama (Mistral LLM), LangChain, LangGraph
    - **Parsing:** PDFPlumber, Python-DOCX
    - **Storage:** SQLite (Caching)
    - **Cloud:** Google Drive API
    
    ## üë®‚Äçüíª Developer
    
    Built by **Rishabh Dinesh Singh**
    - üíº Data Engineer at Aretove Technologies
    - üìß rishabhdineshsingh@gmail.com
    - üîó [LinkedIn](https://linkedin.com/in/rishabhdineshsingh)
    - üêô [GitHub](https://github.com/Rishabhsingh11)
    
    ## üìú Version
    
    **v1.0.0** - Phase 1 Complete
    - ‚úÖ Resume parsing
    - ‚úÖ Job matching
    - ‚úÖ Quality assessment
    - ‚úÖ Intelligent caching
    
    **Coming Soon:** Phase 2A - Skills Gap Analysis & Web Search Tools
    """)


if __name__ == "__main__":
    main()
